# BroadenAgentic å¿«é€Ÿå¯åŠ¨æŒ‡å—

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

ç¡®ä¿ä½ çš„ç³»ç»Ÿæ»¡è¶³ä»¥ä¸‹è¦æ±‚ï¼š
- **Python**: 3.9+ (æ¨è3.11+)
- **ç¡¬ä»¶**: RTX 3060 GPU, 16GB RAM
- **ç³»ç»Ÿ**: Windows 11 (æ¨è)

### 2. å®‰è£…Ollamaå’ŒQwenæ¨¡å‹

```bash
# å®‰è£…Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# æ‹‰å–Qwen3-8Bæ¨¡å‹
ollama pull qwen3:8b

# éªŒè¯æ¨¡å‹
ollama run qwen3:8b "Hello, world!"
```

### 3. å®‰è£…Pythonä¾èµ–

```bash
# å®‰è£…åŸºç¡€ä¾èµ–
pip install fastapi uvicorn pydantic

# å®‰è£…å®Œæ•´ä¾èµ–
pip install -r requirements.txt
```

### 4. è¿è¡Œç³»ç»Ÿæµ‹è¯•

```bash
# æµ‹è¯•ç³»ç»Ÿæ˜¯å¦æ­£å¸¸å·¥ä½œ
python test_system.py
```

### 5. å¯åŠ¨åº”ç”¨

```bash
# æ–¹å¼1: ä½¿ç”¨å¯åŠ¨è„šæœ¬
python run.py

# æ–¹å¼2: ç›´æ¥å¯åŠ¨
python -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

### 6. è®¿é—®åº”ç”¨

- **APIæ–‡æ¡£**: http://localhost:8000/docs
- **å¥åº·æ£€æŸ¥**: http://localhost:8000/health
- **æ ¹è·¯å¾„**: http://localhost:8000/

## ğŸ“– ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€LLMä½¿ç”¨

```python
import asyncio
from app.core.llm import LLMConfig, QwenLLM

async def basic_example():
    # åˆ›å»ºLLMé…ç½®
    config = LLMConfig(
        model_name="qwen3:8b",
        temperature=0.7,
        max_tokens=100
    )
    
    # åˆ›å»ºLLMå®ä¾‹
    llm = QwenLLM(config)
    await llm.load_model()
    
    # ç”Ÿæˆæ–‡æœ¬
    result = await llm.generate("è¯·ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½")
    print(result.text)

asyncio.run(basic_example())
```

### åˆ›å»ºAgent

```python
import asyncio
from app.core.llm import LLMConfig, QwenLLM
from app.core.agent import AgentConfig, AgentBase
from app.core.constraint import InputTypeConstraint, OutputTypeConstraint, OutputCriterion

async def agent_example():
    # åˆ›å»ºLLM
    llm_config = LLMConfig(model_name="qwen3:8b")
    llm = QwenLLM(llm_config)
    await llm.load_model()
    
    # åˆ›å»ºçº¦æŸ
    input_constraints = [
        InputTypeConstraint(
            name="text",
            data_type="string",
            min_length=1,
            max_length=1000
        )
    ]
    
    output_constraints = [
        OutputTypeConstraint(
            name="response",
            data_type="string",
            min_length=10,
            max_length=500
        )
    ]
    
    # åˆ›å»ºè¾“å‡ºæ ‡å‡†
    output_criterion = OutputCriterion(
        name="è´¨é‡è¯„ä¼°",
        description="è¾“å‡ºåº”è¯¥å‡†ç¡®ã€å®Œæ•´ä¸”æœ‰ç”¨",
        min_score=0.7
    )
    
    # åˆ›å»ºAgent
    agent_config = AgentConfig(
        name="æ–‡æœ¬åˆ†æAgent",
        description="åˆ†æè¾“å…¥çš„æ–‡æœ¬å¹¶æä¾›è§è§£",
        input_constraints=input_constraints,
        output_constraints=output_constraints,
        output_criterion=output_criterion
    )
    
    agent = AgentBase(agent_config, llm)
    
    # æ‰§è¡ŒAgent
    result = await agent.execute("äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯")
    print(result)

asyncio.run(agent_example())
```

## ğŸ”§ APIä½¿ç”¨

### åˆ›å»ºAgent

```bash
curl -X POST "http://localhost:8000/api/v1/agent/create" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "æ–‡æœ¬åˆ†æAgent",
    "description": "åˆ†æè¾“å…¥çš„æ–‡æœ¬å¹¶æä¾›è§è§£",
    "input_data": "æµ‹è¯•è¾“å…¥",
    "input_constraints": [
      {
        "name": "text",
        "data_type": "string",
        "min_length": 1,
        "max_length": 1000
      }
    ],
    "output_constraints": [
      {
        "name": "response",
        "data_type": "string",
        "min_length": 10,
        "max_length": 500
      }
    ],
    "output_criterion": {
      "name": "è´¨é‡è¯„ä¼°",
      "description": "è¾“å‡ºåº”è¯¥å‡†ç¡®ã€å®Œæ•´ä¸”æœ‰ç”¨",
      "min_score": 0.7
    }
  }'
```

### æ‰§è¡ŒAgent

```bash
curl -X POST "http://localhost:8000/api/v1/agent/æ–‡æœ¬åˆ†æAgent/execute" \
  -H "Content-Type: application/json" \
  -d '{
    "input_data": "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯"
  }'
```

### è·å–AgentçŠ¶æ€

```bash
curl -X GET "http://localhost:8000/api/v1/agent/æ–‡æœ¬åˆ†æAgent/status"
```

## ğŸ¯ æ ¸å¿ƒç‰¹æ€§

### 1. Promptå·¥ç¨‹å¸ˆå‹å¥½
- å¯è§†åŒ–Promptè°ƒä¼˜å·¥å…·
- A/Bæµ‹è¯•ç•Œé¢
- å®æ—¶Prompté¢„è§ˆ
- è‡ªåŠ¨Promptä¼˜åŒ–å»ºè®®

### 2. å¯å½’å› æ€§å’Œå¯é‡åŒ–æ€§
- å®Œæ•´çš„å†³ç­–è¿‡ç¨‹è¿½è¸ª
- å®¢è§‚çš„è¯„ä¼°æŒ‡æ ‡
- é€æ˜åº¦æŠ¥å‘Šç”Ÿæˆ
- æ€§èƒ½ç›‘æ§å’Œæˆæœ¬åˆ†æ

### 3. æœ¬åœ°åŒ–ä¼˜å…ˆ
- åŸºäºQwen3-8B-Int4æ¨¡å‹
- é€šè¿‡Ollamaæœ¬åœ°éƒ¨ç½²
- å‡å°‘APIä¾èµ–
- æ”¯æŒRTX 3060ç­‰æ¶ˆè´¹çº§GPU

### 4. çº¦æŸç³»ç»Ÿ
- è¾“å…¥è¾“å‡ºç±»å‹çº¦æŸéªŒè¯
- è‡ªç„¶è¯­è¨€è´¨é‡æ ‡å‡†
- è‡ªåŠ¨è´¨é‡è¯„ä¼°å’Œä¼˜åŒ–
- æ™ºèƒ½é‡è¯•æœºåˆ¶

## ğŸ› æ•…éšœæ’é™¤

### 1. Ollamaè¿æ¥å¤±è´¥
```bash
# æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦è¿è¡Œ
ollama list

# é‡å¯OllamaæœåŠ¡
ollama serve
```

### 2. æ¨¡å‹åŠ è½½å¤±è´¥
```bash
# æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½
ollama list

# é‡æ–°ä¸‹è½½æ¨¡å‹
ollama pull qwen2.5:7b
```

### 3. å†…å­˜ä¸è¶³
- ç¡®ä¿æœ‰è¶³å¤Ÿçš„GPUå†…å­˜
- è€ƒè™‘ä½¿ç”¨æ›´å°çš„æ¨¡å‹
- è°ƒæ•´batch_sizeå‚æ•°

### 4. ä¾èµ–å®‰è£…å¤±è´¥
```bash
# å‡çº§pip
pip install --upgrade pip

# ä½¿ç”¨å›½å†…é•œåƒ
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
```

## ğŸ“š æ›´å¤šèµ„æº

- **å®Œæ•´æ–‡æ¡£**: æŸ¥çœ‹ `docs/` ç›®å½•
- **APIæ–‡æ¡£**: http://localhost:8000/docs
- **ç¤ºä¾‹ä»£ç **: æŸ¥çœ‹ `examples/` ç›®å½•
- **æµ‹è¯•ä»£ç **: æŸ¥çœ‹ `tests/` ç›®å½•

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ä»£ç å’Œæå‡ºå»ºè®®ï¼

1. Fork é¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. æäº¤æ›´æ”¹
4. æ¨é€åˆ°åˆ†æ”¯
5. åˆ›å»º Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚ 