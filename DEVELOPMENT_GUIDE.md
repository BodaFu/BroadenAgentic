# BroadenAgentic å¼€å‘æŒ‡å—

## ğŸ¯ å¼€å‘æ¦‚è¿°

BroadenAgenticæ˜¯ä¸€ä¸ªæ¨¡å—åŒ–çš„æ™ºèƒ½Agentæ¡†æ¶ï¼Œè®¾è®¡ç›®æ ‡æ˜¯è®©å¼€å‘è€…èƒ½å¤Ÿè½»æ¾æ‰©å±•å’Œå®šåˆ¶åŠŸèƒ½ã€‚æœ¬æŒ‡å—å°†è¯¦ç»†ä»‹ç»å¦‚ä½•å‚ä¸å¼€å‘å’Œæ‰©å±•æ¡†æ¶åŠŸèƒ½ã€‚

## ğŸ—ï¸ æ¶æ„è®¾è®¡åŸåˆ™

### 1. æ¨¡å—åŒ–è®¾è®¡
- æ¯ä¸ªæ¨¡å—éƒ½æœ‰æ¸…æ™°çš„èŒè´£è¾¹ç•Œ
- æ¨¡å—é—´é€šè¿‡æ ‡å‡†æ¥å£é€šä¿¡
- æ”¯æŒæ’æ‹”å¼æ‰©å±•

### 2. å¼‚æ­¥ä¼˜å…ˆ
- æ‰€æœ‰I/Oæ“ä½œéƒ½æ˜¯å¼‚æ­¥çš„
- æ”¯æŒé«˜å¹¶å‘å¤„ç†
- é¿å…é˜»å¡æ“ä½œ

### 3. ç±»å‹å®‰å…¨
- ä½¿ç”¨Pydanticè¿›è¡Œæ•°æ®éªŒè¯
- å®Œæ•´çš„ç±»å‹æ³¨è§£
- è¿è¡Œæ—¶ç±»å‹æ£€æŸ¥

### 4. å¯æµ‹è¯•æ€§
- æ¯ä¸ªæ¨¡å—éƒ½æœ‰å¯¹åº”çš„æµ‹è¯•
- æ”¯æŒå•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•
- æä¾›æµ‹è¯•å·¥å…·å’Œmock

## ğŸ§  æ ¸å¿ƒæ¨¡å—å¼€å‘

### 1. LLMæ¨¡å—å¼€å‘

#### æ·»åŠ æ–°çš„LLMå®ç°

1. **ç»§æ‰¿LLMBaseç±»**
```python
from app.core.llm.base import LLMBase, LLMConfig, GenerationResult

class MyCustomLLM(LLMBase):
    def __init__(self, config: LLMConfig):
        super().__init__(config)
        # åˆå§‹åŒ–ä½ çš„LLM
    
    async def load_model(self) -> bool:
        """åŠ è½½æ¨¡å‹"""
        try:
            # å®ç°æ¨¡å‹åŠ è½½é€»è¾‘
            self._is_loaded = True
            return True
        except Exception as e:
            logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    async def generate(self, prompt: str, **kwargs) -> GenerationResult:
        """ç”Ÿæˆæ–‡æœ¬"""
        if not self._is_loaded:
            await self.load_model()
        
        # å®ç°æ–‡æœ¬ç”Ÿæˆé€»è¾‘
        response = await self._call_model(prompt, **kwargs)
        
        return GenerationResult(
            text=response.text,
            tokens_used=response.tokens,
            finish_reason=response.finish_reason
        )
    
    async def health_check(self) -> bool:
        """å¥åº·æ£€æŸ¥"""
        try:
            # å®ç°å¥åº·æ£€æŸ¥é€»è¾‘
            return True
        except Exception:
            return False
```

2. **åœ¨å·¥å‚ä¸­æ³¨å†Œ**
```python
# åœ¨app/core/llm/factory.pyä¸­æ·»åŠ 
async def _create_custom_llm(self, llm_config: LLMConfig) -> LLMBase:
    """åˆ›å»ºè‡ªå®šä¹‰LLM"""
    return MyCustomLLM(llm_config)
```

#### LLMé…ç½®æ‰©å±•

```python
from pydantic import BaseModel, Field

class MyCustomLLMConfig(BaseModel):
    """è‡ªå®šä¹‰LLMé…ç½®"""
    api_key: str = Field(..., description="APIå¯†é’¥")
    custom_param: str = Field(default="default", description="è‡ªå®šä¹‰å‚æ•°")
```

### 2. Agentæ¨¡å—å¼€å‘

#### åˆ›å»ºä¸“ç”¨Agent

```python
from app.core.agent.base import AgentBase, AgentConfig
from app.core.constraint import InputTypeConstraint, OutputTypeConstraint

class MySpecializedAgent(AgentBase):
    """ä¸“ç”¨Agentç¤ºä¾‹"""
    
    def __init__(self, config: AgentConfig, llm):
        super().__init__(config, llm)
        # åˆå§‹åŒ–ä¸“ç”¨åŠŸèƒ½
    
    async def _process_special_task(self, input_data: str) -> str:
        """å¤„ç†ç‰¹æ®Šä»»åŠ¡"""
        # å®ç°ç‰¹æ®Šä»»åŠ¡å¤„ç†é€»è¾‘
        return f"å¤„ç†ç»“æœ: {input_data}"
    
    async def execute(self, input_data: Any) -> str:
        """æ‰§è¡Œä»»åŠ¡"""
        # éªŒè¯è¾“å…¥
        self._validate_input(input_data)
        
        # å¤„ç†ç‰¹æ®Šä»»åŠ¡
        result = await self._process_special_task(str(input_data))
        
        # éªŒè¯è¾“å‡º
        self._validate_output(result)
        
        return result
```

#### Agenté…ç½®ç¤ºä¾‹

```python
# åˆ›å»ºä¸“ç”¨Agenté…ç½®
specialized_config = AgentConfig(
    name="ä¸“ç”¨åˆ†æAgent",
    description="ä¸“é—¨å¤„ç†ç‰¹å®šç±»å‹ä»»åŠ¡",
    input_constraints=[
        InputTypeConstraint(
            name="data",
            data_type="string",
            min_length=1,
            max_length=1000
        )
    ],
    output_constraints=[
        OutputTypeConstraint(
            name="analysis",
            data_type="string"
        )
    ],
    output_criterion=OutputCriterion(
        name="ä¸“ç”¨æ ‡å‡†",
        description="è¾“å‡ºåº”ç¬¦åˆä¸“ç”¨è¦æ±‚",
        min_score=0.8
    )
)
```

### 3. çº¦æŸç³»ç»Ÿå¼€å‘

#### åˆ›å»ºè‡ªå®šä¹‰çº¦æŸ

```python
from app.core.constraint.input import InputTypeConstraint

class CustomInputConstraint(InputTypeConstraint):
    """è‡ªå®šä¹‰è¾“å…¥çº¦æŸ"""
    
    def validate(self, data: Any) -> bool:
        """è‡ªå®šä¹‰éªŒè¯é€»è¾‘"""
        # è°ƒç”¨çˆ¶ç±»éªŒè¯
        if not super().validate(data):
            return False
        
        # æ·»åŠ è‡ªå®šä¹‰éªŒè¯é€»è¾‘
        if isinstance(data, str):
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ç‰¹å®šå…³é”®è¯
            if "æ•æ„Ÿè¯" in data:
                return False
        
        return True
    
    def get_error_message(self, data: Any) -> Optional[str]:
        """è‡ªå®šä¹‰é”™è¯¯æ¶ˆæ¯"""
        if not self.validate(data):
            return "æ•°æ®åŒ…å«æ•æ„Ÿå†…å®¹"
        return None
```

#### åˆ›å»ºè‡ªå®šä¹‰è¾“å‡ºæ ‡å‡†

```python
from app.core.constraint.criterion import OutputCriterion

class CustomOutputCriterion(OutputCriterion):
    """è‡ªå®šä¹‰è¾“å‡ºæ ‡å‡†"""
    
    async def evaluate(self, output: str, llm) -> Dict[str, Any]:
        """è‡ªå®šä¹‰è¯„ä¼°é€»è¾‘"""
        # å®ç°è‡ªå®šä¹‰è¯„ä¼°é€»è¾‘
        score = await self._custom_evaluation(output, llm)
        
        return {
            "score": score,
            "feedback": "è‡ªå®šä¹‰åé¦ˆ",
            "suggestions": ["æ”¹è¿›å»ºè®®1", "æ”¹è¿›å»ºè®®2"]
        }
    
    async def _custom_evaluation(self, output: str, llm) -> float:
        """è‡ªå®šä¹‰è¯„ä¼°æ–¹æ³•"""
        # å®ç°å…·ä½“çš„è¯„ä¼°é€»è¾‘
        return 0.85
```

## ğŸ”§ å·¥å…·å’Œå·¥å…·Agentå¼€å‘

### 1. åˆ›å»ºå·¥å…·

```python
from typing import Any, Dict
import requests

class WebSearchTool:
    """ç½‘ç»œæœç´¢å·¥å…·"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
    
    async def search(self, query: str) -> Dict[str, Any]:
        """æ‰§è¡Œæœç´¢"""
        try:
            # å®ç°æœç´¢é€»è¾‘
            response = requests.get(
                f"https://api.search.com/search?q={query}&key={self.api_key}"
            )
            return {
                "results": response.json(),
                "status": "success"
            }
        except Exception as e:
            return {
                "error": str(e),
                "status": "error"
            }
```

### 2. åˆ›å»ºå·¥å…·Agent

```python
from app.core.agent.tool import ToolAgent

class WebSearchAgent(ToolAgent):
    """ç½‘ç»œæœç´¢Agent"""
    
    def __init__(self, config: AgentConfig, llm, search_tool: WebSearchTool):
        super().__init__(config, llm)
        self.search_tool = search_tool
    
    async def execute(self, input_data: str) -> str:
        """æ‰§è¡Œæœç´¢ä»»åŠ¡"""
        # éªŒè¯è¾“å…¥
        self._validate_input(input_data)
        
        # æ‰§è¡Œæœç´¢
        search_results = await self.search_tool.search(input_data)
        
        # ä½¿ç”¨LLMå¤„ç†ç»“æœ
        prompt = f"åŸºäºä»¥ä¸‹æœç´¢ç»“æœï¼Œå›ç­”é—®é¢˜: {input_data}\n\næœç´¢ç»“æœ: {search_results}"
        result = await self.llm.generate(prompt)
        
        # éªŒè¯è¾“å‡º
        self._validate_output(result.text)
        
        return result.text
```

## ğŸ§ª æµ‹è¯•å¼€å‘

### 1. å•å…ƒæµ‹è¯•

```python
import pytest
from unittest.mock import Mock, AsyncMock
from app.core.llm import LLMConfig, QwenLLM

class TestQwenLLM:
    """QwenLLMæµ‹è¯•ç±»"""
    
    @pytest.fixture
    def llm_config(self):
        """LLMé…ç½®fixture"""
        return LLMConfig(
            model_name="qwen3:8b",
            temperature=0.7,
            max_tokens=100
        )
    
    @pytest.fixture
    def mock_ollama_client(self):
        """Mock Ollamaå®¢æˆ·ç«¯"""
        client = Mock()
        client.generate = AsyncMock(return_value={
            "response": "æµ‹è¯•å“åº”",
            "done": True
        })
        return client
    
    @pytest.mark.asyncio
    async def test_generate_text(self, llm_config, mock_ollama_client):
        """æµ‹è¯•æ–‡æœ¬ç”Ÿæˆ"""
        llm = QwenLLM(llm_config)
        llm._client = mock_ollama_client
        
        result = await llm.generate("æµ‹è¯•æç¤º")
        
        assert result.text == "æµ‹è¯•å“åº”"
        assert result.tokens_used is not None
```

### 2. é›†æˆæµ‹è¯•

```python
import pytest
from app.core.agent import AgentConfig, AgentBase
from app.core.constraint import InputTypeConstraint, OutputTypeConstraint

class TestAgentIntegration:
    """Agenté›†æˆæµ‹è¯•"""
    
    @pytest.fixture
    def mock_llm(self):
        """Mock LLM"""
        llm = Mock()
        llm.generate = AsyncMock(return_value=Mock(
            text="æµ‹è¯•è¾“å‡º",
            tokens_used=10
        ))
        return llm
    
    @pytest.mark.asyncio
    async def test_agent_execution(self, mock_llm):
        """æµ‹è¯•Agentæ‰§è¡Œ"""
        config = AgentConfig(
            name="æµ‹è¯•Agent",
            description="æµ‹è¯•ç”¨Agent",
            input_constraints=[
                InputTypeConstraint(
                    name="input",
                    data_type="string",
                    min_length=1
                )
            ],
            output_constraints=[
                OutputTypeConstraint(
                    name="output",
                    data_type="string"
                )
            ]
        )
        
        agent = AgentBase(config, mock_llm)
        result = await agent.execute("æµ‹è¯•è¾“å…¥")
        
        assert result == "æµ‹è¯•è¾“å‡º"
```

### 3. æ€§èƒ½æµ‹è¯•

```python
import asyncio
import time
from app.core.llm import LLMFactory, LLMFactoryConfig

class TestPerformance:
    """æ€§èƒ½æµ‹è¯•ç±»"""
    
    @pytest.mark.asyncio
    async def test_llm_performance(self):
        """æµ‹è¯•LLMæ€§èƒ½"""
        config = LLMFactoryConfig(
            preferred_mode="local",
            local_model_name="qwen3:8b"
        )
        
        factory = LLMFactory(config)
        llm = await factory.create_llm()
        
        # æµ‹è¯•å“åº”æ—¶é—´
        start_time = time.time()
        result = await llm.generate("æ€§èƒ½æµ‹è¯•")
        end_time = time.time()
        
        response_time = end_time - start_time
        assert response_time < 120  # 2åˆ†é’Ÿå†…å®Œæˆ
        assert result.text is not None
```

## ğŸ” è°ƒè¯•å’Œæ—¥å¿—

### 1. æ—¥å¿—é…ç½®

```python
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('broadenagentic.log'),
        logging.StreamHandler()
    ]
)

# æ¨¡å—çº§æ—¥å¿—
logger = logging.getLogger(__name__)
```

### 2. è°ƒè¯•å·¥å…·

```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
import logging
logging.getLogger('app').setLevel(logging.DEBUG)

# ä½¿ç”¨pdbè°ƒè¯•
import pdb
pdb.set_trace()

# ä½¿ç”¨ipdbè°ƒè¯•ï¼ˆæ¨èï¼‰
import ipdb
ipdb.set_trace()
```

### 3. æ€§èƒ½åˆ†æ

```python
import cProfile
import pstats

def profile_function():
    """æ€§èƒ½åˆ†æè£…é¥°å™¨"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            profiler = cProfile.Profile()
            profiler.enable()
            result = func(*args, **kwargs)
            profiler.disable()
            
            stats = pstats.Stats(profiler)
            stats.sort_stats('cumulative')
            stats.print_stats(10)
            
            return result
        return wrapper
    return decorator

# ä½¿ç”¨ç¤ºä¾‹
@profile_function()
async def my_function():
    # ä½ çš„ä»£ç 
    pass
```

## ğŸ“¦ æ‰“åŒ…å’Œéƒ¨ç½²

### 1. åˆ›å»ºsetup.py

```python
from setuptools import setup, find_packages

setup(
    name="broadenagentic",
    version="1.0.0",
    description="Promptå·¥ç¨‹å¸ˆå‹å¥½çš„Agentic AIæ¡†æ¶",
    author="Your Name",
    author_email="your.email@example.com",
    packages=find_packages(),
    install_requires=[
        "fastapi>=0.104.0",
        "uvicorn>=0.24.0",
        "pydantic>=2.0.0",
        "ollama>=0.5.0",
        "openai>=1.0.0",
        "httpx>=0.24.0",
    ],
    extras_require={
        "dev": [
            "pytest>=7.0.0",
            "pytest-asyncio>=0.21.0",
            "pytest-cov>=4.0.0",
            "black>=23.0.0",
            "isort>=5.12.0",
            "mypy>=1.0.0",
        ]
    },
    python_requires=">=3.9",
)
```

### 2. åˆ›å»ºDockerfile

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£…Ollama
RUN curl -fsSL https://ollama.ai/install.sh | sh

# å¤åˆ¶é¡¹ç›®æ–‡ä»¶
COPY requirements.txt .
COPY app/ ./app/
COPY run.py .

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt

# æ‹‰å–æ¨¡å‹
RUN ollama pull qwen3:8b

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¯åŠ¨å‘½ä»¤
CMD ["python", "run.py"]
```

### 3. åˆ›å»ºdocker-compose.yml

```yaml
version: '3.8'

services:
  app:
    build: .
    ports:
      - "8000:8000"
    environment:
      - OLLAMA_HOST=http://ollama:11434
      - QWEN_API_KEY=${QWEN_API_KEY}
    depends_on:
      - ollama
    volumes:
      - ./data:/app/data

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama

volumes:
  ollama_data:
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

### 1. å¼€å‘æµç¨‹

1. **Forké¡¹ç›®**
2. **åˆ›å»ºåŠŸèƒ½åˆ†æ”¯**
   ```bash
   git checkout -b feature/your-feature-name
   ```
3. **ç¼–å†™ä»£ç å’Œæµ‹è¯•**
4. **è¿è¡Œæµ‹è¯•**
   ```bash
   pytest
   ```
5. **æäº¤ä»£ç **
   ```bash
   git commit -m "feat: add your feature"
   ```
6. **æ¨é€åˆ†æ”¯**
   ```bash
   git push origin feature/your-feature-name
   ```
7. **åˆ›å»ºPull Request**

### 2. ä»£ç è§„èŒƒ

- ä½¿ç”¨Blackè¿›è¡Œä»£ç æ ¼å¼åŒ–
- ä½¿ç”¨isortè¿›è¡Œå¯¼å…¥æ’åº
- ä½¿ç”¨mypyè¿›è¡Œç±»å‹æ£€æŸ¥
- éµå¾ªPEP 8è§„èŒƒ

```bash
# æ ¼å¼åŒ–ä»£ç 
black app/ tests/

# æ’åºå¯¼å…¥
isort app/ tests/

# ç±»å‹æ£€æŸ¥
mypy app/
```

### 3. æµ‹è¯•è¦æ±‚

- æ–°åŠŸèƒ½å¿…é¡»æœ‰å¯¹åº”çš„æµ‹è¯•
- æµ‹è¯•è¦†ç›–ç‡ä¸ä½äº80%
- æ‰€æœ‰æµ‹è¯•å¿…é¡»é€šè¿‡

```bash
# è¿è¡Œæµ‹è¯•å¹¶ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=app --cov-report=html
```

## ğŸ“š å­¦ä¹ èµ„æº

### 1. ç›¸å…³æ–‡æ¡£
- [FastAPIæ–‡æ¡£](https://fastapi.tiangolo.com/)
- [Pydanticæ–‡æ¡£](https://pydantic-docs.helpmanual.io/)
- [Ollamaæ–‡æ¡£](https://ollama.ai/docs)
- [Qwenæ–‡æ¡£](https://github.com/QwenLM/Qwen)

### 2. è®¾è®¡æ¨¡å¼
- å·¥å‚æ¨¡å¼ï¼šLLMå·¥å‚
- ç­–ç•¥æ¨¡å¼ï¼šä¸åŒçš„LLMå®ç°
- è£…é¥°å™¨æ¨¡å¼ï¼šçº¦æŸéªŒè¯
- è§‚å¯Ÿè€…æ¨¡å¼ï¼šäº‹ä»¶ç³»ç»Ÿ

### 3. æœ€ä½³å®è·µ
- å¼‚æ­¥ç¼–ç¨‹
- é”™è¯¯å¤„ç†
- æ—¥å¿—è®°å½•
- æ€§èƒ½ä¼˜åŒ–
- å®‰å…¨è€ƒè™‘

## ğŸ”® æœªæ¥è§„åˆ’

### 1. çŸ­æœŸç›®æ ‡
- æ·»åŠ æ›´å¤šLLMæ”¯æŒ
- å®Œå–„çº¦æŸç³»ç»Ÿ
- ä¼˜åŒ–æ€§èƒ½
- å¢å¼ºæµ‹è¯•è¦†ç›–

### 2. ä¸­æœŸç›®æ ‡
- æ·»åŠ Webç•Œé¢
- æ”¯æŒå¤šæ¨¡æ€è¾“å…¥
- å®ç°åˆ†å¸ƒå¼éƒ¨ç½²
- æ·»åŠ ç›‘æ§å’Œå‘Šè­¦

### 3. é•¿æœŸç›®æ ‡
- æ„å»ºç”Ÿæ€ç³»ç»Ÿ
- æ”¯æŒæ’ä»¶ç³»ç»Ÿ
- å®ç°è‡ªåŠ¨ä¼˜åŒ–
- æ”¯æŒä¼ä¸šçº§éƒ¨ç½² 